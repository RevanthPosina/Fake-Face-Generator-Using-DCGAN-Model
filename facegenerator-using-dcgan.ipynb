{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torchvision import transforms","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:13:34.272025Z","iopub.execute_input":"2021-10-26T13:13:34.272726Z","iopub.status.idle":"2021-10-26T13:13:35.934761Z","shell.execute_reply.started":"2021-10-26T13:13:34.272685Z","shell.execute_reply":"2021-10-26T13:13:35.934017Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torchvision import datasets\nfrom torchvision import transforms","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:22:01.709406Z","iopub.execute_input":"2021-10-26T13:22:01.710158Z","iopub.status.idle":"2021-10-26T13:22:01.714542Z","shell.execute_reply.started":"2021-10-26T13:22:01.710115Z","shell.execute_reply":"2021-10-26T13:22:01.713794Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_dataloader(batch_size, image_size, data_dir='../input/celeba-dataset'):\n   \n    transform = transforms.Compose([transforms.Resize(image_size),transforms.CenterCrop(image_size),transforms.ToTensor()])\n  \n    dataset = datasets.ImageFolder(data_dir,transform = transform)\n    \n    dataloader = torch.utils.data.DataLoader(dataset = dataset,batch_size = batch_size,shuffle = True)\n    return dataloader\n# Defining function hyperparameters\nbatch_size = 256\nimg_size = 32\n# Calling function and get a dataloader\nceleba_train_loader = get_dataloader(batch_size, img_size)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:22:25.646427Z","iopub.execute_input":"2021-10-26T13:22:25.646682Z","iopub.status.idle":"2021-10-26T13:22:52.590689Z","shell.execute_reply.started":"2021-10-26T13:22:25.646651Z","shell.execute_reply":"2021-10-26T13:22:52.589967Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import pickle as pkl\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:24:10.241822Z","iopub.execute_input":"2021-10-26T13:24:10.242508Z","iopub.status.idle":"2021-10-26T13:24:10.245673Z","shell.execute_reply.started":"2021-10-26T13:24:10.242463Z","shell.execute_reply":"2021-10-26T13:24:10.245004Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n# obtaining one batch of training images\ndataiter = iter(celeba_train_loader)\nimages, _ = dataiter.next() # _ for no labels\n# ploting the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(20, 4))\nplot_size=20\nfor idx in np.arange(plot_size):\n    ax = fig.add_subplot(2, plot_size/2, idx+1, xticks=[], yticks=[])\n    imshow(images[idx])","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:24:13.101568Z","iopub.execute_input":"2021-10-26T13:24:13.102115Z","iopub.status.idle":"2021-10-26T13:24:14.795235Z","shell.execute_reply.started":"2021-10-26T13:24:13.102076Z","shell.execute_reply":"2021-10-26T13:24:14.794577Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def scale(x, feature_range=(-1, 1)):\n    \n    # by assuming x is scaled to (0, 1)\n    # the scale to feature_range and return scaled x\n    min, max = feature_range\n    x = x*(max-min) + min\n    return x","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:24:53.794670Z","iopub.execute_input":"2021-10-26T13:24:53.795350Z","iopub.status.idle":"2021-10-26T13:24:53.799810Z","shell.execute_reply.started":"2021-10-26T13:24:53.795311Z","shell.execute_reply":"2021-10-26T13:24:53.798873Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:28:33.308870Z","iopub.execute_input":"2021-10-26T13:28:33.309426Z","iopub.status.idle":"2021-10-26T13:28:33.313391Z","shell.execute_reply.started":"2021-10-26T13:28:33.309391Z","shell.execute_reply":"2021-10-26T13:28:33.312513Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def conv(input_c,output,kernel_size,stride = 2,padding  = 1, batch_norm = True):\n    layers =[]\n    con = nn.Conv2d(input_c,output,kernel_size,stride,padding,bias = False)\n    layers.append(con)\n    \n    if batch_norm:\n        layers.append(nn.BatchNorm2d(output))\n    \n    return nn.Sequential(*layers)\nclass Discriminator(nn.Module):\n    def __init__(self, conv_dim):\n        super(Discriminator, self).__init__()\n        self.conv_dim = conv_dim\n        self.layer_1 = conv(3,conv_dim,4,batch_norm = False) #16\n        self.layer_2 = conv(conv_dim,conv_dim*2,4) #8\n        self.layer_3 = conv(conv_dim*2,conv_dim*4,4) #4\n        self.fc = nn.Linear(conv_dim*4*4*4,1)\ndef forward(self, x):\n        \n        # defining feedforward behavior\n        x = F.leaky_relu(self.layer_1(x))\n        x = F.leaky_relu(self.layer_2(x))\n        x = F.leaky_relu(self.layer_3(x))\n        x = x.view(-1,self.conv_dim*4*4*4)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:28:37.033782Z","iopub.execute_input":"2021-10-26T13:28:37.034620Z","iopub.status.idle":"2021-10-26T13:28:37.045635Z","shell.execute_reply.started":"2021-10-26T13:28:37.034565Z","shell.execute_reply":"2021-10-26T13:28:37.044902Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def deconv(input_c,output,kernel_size,stride = 2, padding =1, batch_norm = True):\n    layers = []\n    decon = nn.ConvTranspose2d(input_c,output,kernel_size,stride,padding,bias = False)\n    layers.append(decon)\n    \n    if batch_norm:\n        layers.append(nn.BatchNorm2d(output))\n    return nn.Sequential(*layers)\nclass Generator(nn.Module):\n    \n    def __init__(self, z_size, conv_dim):\n        \n        super(Generator, self).__init__()\n        \n        self.conv_dim = conv_dim\n        self.fc = nn.Linear(z_size,conv_dim*8*2*2)\n        self.layer_1 = deconv(conv_dim*8,conv_dim*4,4) #4\n        self.layer_2 = deconv(conv_dim*4,conv_dim*2,4) #8\n        self.layer_3 = deconv(conv_dim*2,conv_dim,4) #16\n        self.layer_4 = deconv(conv_dim,3,4,batch_norm = False) #32\n        \n        \n    def forward(self, x):\n       \n        # define feedforward behavior\n        x = self.fc(x)\n        x = x.view(-1,self.conv_dim*8,2,2) #(batch_size,depth,width,height)\n        x = F.relu(self.layer_1(x))\n        x = F.relu(self.layer_2(x))\n        x = F.relu(self.layer_3(x))\n        x = torch.tanh(self.layer_4(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:29:20.242526Z","iopub.execute_input":"2021-10-26T13:29:20.242793Z","iopub.status.idle":"2021-10-26T13:29:20.253868Z","shell.execute_reply.started":"2021-10-26T13:29:20.242761Z","shell.execute_reply":"2021-10-26T13:29:20.253000Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def weights_init_normal(m):\n    classname = m.__class__.__name__\n    \n    if hasattr(m,'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n        \n        m.weight.data.normal_(0.0,0.02)\n    \n        if hasattr(m,'bias') and m.bias is not None:\n            m.bias.data.zero_()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:30:18.036802Z","iopub.execute_input":"2021-10-26T13:30:18.037361Z","iopub.status.idle":"2021-10-26T13:30:18.044650Z","shell.execute_reply.started":"2021-10-26T13:30:18.037318Z","shell.execute_reply":"2021-10-26T13:30:18.043658Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def build_network(d_conv_dim, g_conv_dim, z_size):\n    \n    D = Discriminator(d_conv_dim)\n    G = Generator(z_size=z_size, conv_dim=g_conv_dim)\n\n    D.apply(weights_init_normal)\n    G.apply(weights_init_normal)\n    print(D)\n    print()\n    print(G)\n    \n    return D, G\n   \n# Defining the model hyperparams\nd_conv_dim = 64\ng_conv_dim = 64\nz_size = 100\nD, G = build_network(d_conv_dim, g_conv_dim, z_size)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:31:02.322899Z","iopub.execute_input":"2021-10-26T13:31:02.323591Z","iopub.status.idle":"2021-10-26T13:31:02.396546Z","shell.execute_reply.started":"2021-10-26T13:31:02.323519Z","shell.execute_reply":"2021-10-26T13:31:02.395746Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def real_loss(D_out):\n    #real loss\n    batch_size = D_out.size(0)\n    labels = torch.ones(batch_size)\n    if train_on_gpu:\n        labels = labels.cuda()\n    criterion = nn.BCEWithLogitsLoss()\n    loss = criterion(D_out.squeeze(),labels)\n    return loss\ndef fake_loss(D_out):\n    #fake loss\n    batch_size = D_out.size(0)\n    labels = torch.zeros(batch_size)\n    if train_on_gpu:\n        labels = labels.cuda()\n    criterion =  nn.BCEWithLogitsLoss()\n    loss = criterion(D_out.squeeze(),labels)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:31:56.523972Z","iopub.execute_input":"2021-10-26T13:31:56.524507Z","iopub.status.idle":"2021-10-26T13:31:56.530523Z","shell.execute_reply.started":"2021-10-26T13:31:56.524470Z","shell.execute_reply":"2021-10-26T13:31:56.529782Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n# Optimizers for the discriminator D and generator G\nd_optimizer = optim.Adam(D.parameters(),lr = .0002, betas = [0.5,0.999])\ng_optimizer = optim.Adam(G.parameters(),lr = .0002, betas = [0.5,0.999])","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:32:45.953606Z","iopub.execute_input":"2021-10-26T13:32:45.953875Z","iopub.status.idle":"2021-10-26T13:32:45.959217Z","shell.execute_reply.started":"2021-10-26T13:32:45.953843Z","shell.execute_reply":"2021-10-26T13:32:45.958496Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Checking for a GPU\ntrain_on_gpu = torch.cuda.is_available()\nif not train_on_gpu:\n    print('No GPU found. Please use a GPU to train your neural network.')\nelse:\n    print('Training on GPU!')","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:44:47.099950Z","iopub.execute_input":"2021-10-26T13:44:47.100525Z","iopub.status.idle":"2021-10-26T13:44:47.156222Z","shell.execute_reply.started":"2021-10-26T13:44:47.100485Z","shell.execute_reply":"2021-10-26T13:44:47.155356Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def train(D, G, n_epochs, print_every=50):\n    '''Trains adversarial networks for some number of epochs\n       param, D: the discriminator network\n       param, G: the generator network\n       param, n_epochs: number of epochs to train for\n       param, print_every: when to print and record the models' losses\n       return: D and G losses'''\n    \n   \n    if train_on_gpu:\n        D.cuda()\n        G.cuda()\n\n    \n    samples = []\n    losses = []\n\n\n    sample_size=16\n    fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n    fixed_z = torch.from_numpy(fixed_z).float()\n    # move z to GPU if available\n    if train_on_gpu:\n        fixed_z = fixed_z.cuda()\n\n    # epoch training loop\n    for epoch in range(n_epochs):\n\n        # batch training loop\n        for batch_i, (real_images, _) in enumerate(celeba_train_loader):\n\n            batch_size = real_images.size(0)\n            real_images = scale(real_images)\n\n            if train_on_gpu:\n                real_images = real_images.cuda()\n            # 1. Train the discriminator on real and fake images\n            d_optimizer.zero_grad()\n            d_out_real = D(real_images)\n            z = np.random.uniform(-1,1,size = (batch_size,z_size))\n            z = torch.from_numpy(z).float()\n            if train_on_gpu:\n                z = z.cuda()\n            d_loss = real_loss(d_out_real) + fake_loss(D(G(z)))\n            d_loss.backward()\n            d_optimizer.step()\n\n            # 2. Train the generator with an adversarial loss\n            G.train()\n            g_optimizer.zero_grad()\n            z = np.random.uniform(-1,1,size = (batch_size,z_size))\n            z = torch.from_numpy(z).float()\n            if train_on_gpu:\n                z = z.cuda()\n            g_loss = real_loss(D(G(z)))\n            g_loss.backward()\n            g_optimizer.step()\n            \n            if batch_i % print_every == 0:\n                \n                losses.append((d_loss.item(), g_loss.item()))\n                \n                print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n                        epoch+1, n_epochs, d_loss.item(), g_loss.item()))\n        G.eval() \n        samples_z = G(fixed_z)\n        samples.append(samples_z)\n        G.train() \n\n    \n    with open('train_samples.pkl', 'wb') as f:\n        pkl.dump(samples, f)\n    \n    # finally return losses\n    return losses","metadata":{"execution":{"iopub.status.busy":"2021-10-26T14:43:37.300997Z","iopub.execute_input":"2021-10-26T14:43:37.301330Z","iopub.status.idle":"2021-10-26T14:43:37.315735Z","shell.execute_reply.started":"2021-10-26T14:43:37.301295Z","shell.execute_reply":"2021-10-26T14:43:37.314813Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"n_epochs = 40\n\n# call training function\nlosses = train(D, G, n_epochs=n_epochs)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T14:44:18.744812Z","iopub.execute_input":"2021-10-26T14:44:18.745621Z","iopub.status.idle":"2021-10-26T14:44:20.431318Z","shell.execute_reply.started":"2021-10-26T14:44:18.745581Z","shell.execute_reply":"2021-10-26T14:44:20.430154Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}